---
title: "model_summary_visualization"
output: html_document
date: "2024-08-08"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, here, lubridate, lme4, loo, rstan, shinystan, truncnorm, MFEUtilities, RColorBrewer, cowplot, bayesplot, cmdstanr, posterior, ggsci, cowplot, geosphere, PerformanceAnalytics, MASS, fitdistrplus)
```

Read in selected model fit, do some visualization on parameter estimates. Then revise model script (generated quantities block) to generate catch predictions for angler skill quantiles at mean popDensity and mean log_q_l, d. Finally, generate catch predictions across popDensities and dates

```{r}
rm(list=ls())
```

```{r}
# raw catch data
wd<-getwd()
db.dir<-paste0(wd, "/MFEdb/")
db<-"MFEdb_20220405.db"

dbTableList(db.dir, db)

lakes<-dbTable("lakes", fpath=db.dir, dbname=db)
#crew<-dbTable("crew", fpath=db.dir, dbname=db)%>%
#  filter(year%in%c("2018","2019"))
#write.csv(crew, "crew.csv")

# lake data

lakes.key<-lakes%>%
  dplyr::select(lakeID, lakeName, lat, long, WBIC, surfaceArea)
# Found lake missing surface area--135.97 ha
lakes.key[lakes.key$lakeID=="FD","surfaceArea"]<-135.97



projects<-dbTable("projects", fpath=db.dir, dbname=db)

fishSamples<-dbTable("fish_samples", fpath=db.dir, dbname=db)%>%
  filter(projectID%in%c("37") & gear=="AN")%>%
    mutate(nAnglers=as.numeric(nAnglers),
    effort=effort/nAnglers)


fishInfo<-dbTable("fish_info", fpath=db.dir, dbname=db)%>%
  filter(sampleID%in%fishSamples$sampleID)%>%
  filter(str_length(caughtBy)<4)%>%
  mutate(caughtBy=str_trim(caughtBy))%>%
  filter(otu=="largemouth_bass")%>%
  dplyr::select(projectID:caughtBy, comments)%>%
  # join fishing effort
  left_join(fishSamples[,c("lakeID","sampleID","dayOfYear","dateSample","dateTimeSample","crew","effort","effortUnits","nAnglers")], by="sampleID")

# catch rates for each angler trip, correcting for some ambiguous initials first

ALK.lake.date<-c("LV_20190608",
                 "SM_20190615",
                 "WN_20190617",
                 "BY_20190622")

AMK.lake.date<-c("DS_20190613",
                 "BOT_20190615",
                 "SM_20190621",
                 "BOT_20190624",
                 "NH_20190713")

long.crew<-fishSamples%>%
    mutate(date=str_split_fixed(sampleID, "_", 4)[,3],
         lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         lakeID_date=paste(lakeID, date, sep="_"))%>%
  mutate(crewFix.ALK=ifelse(lakeID_date%in%ALK.lake.date & grepl("AK", crew), 1, 0),
         crewFix.AMK=ifelse(lakeID_date%in%AMK.lake.date & grepl("AK", crew), 1, 0))%>%
  mutate(crew=ifelse(crewFix.ALK==1, str_replace(crew, "AK", "ALK"), crew),
         crew=ifelse(crewFix.AMK==1, str_replace(crew, "AK", "AMK"), crew))%>%
  group_by(sampleID)%>%
  summarize(crew=unique(crew),
            effort=unique(effort))%>%
  # split crew into columns and then pivot longer
  separate("crew", paste("angler", 1:3, sep="_"), sep=", ", extra="drop")%>%
  pivot_longer(cols=angler_1:angler_3, names_to="angler_num", values_to="caughtBy", values_drop_na=T)%>%
  mutate(caughtBy=ifelse(caughtBy=="CMI","CI", caughtBy))%>%
  mutate(date=str_split_fixed(sampleID, "_", 4)[,3],
         lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         lakeID_date=paste(lakeID, date, sep="_"))

 
 all.data<-fishInfo%>%
  mutate(year=year(dateSample))%>%
  left_join(lakes.key, by="lakeID")
  

  
# now get catch rates from angling data and left join to long.crew. empty values can then be replaced with 0

cpue<-all.data%>%
  group_by(sampleID, caughtBy)%>%
  summarize(nCaught=n())



full.data<-long.crew%>%
  left_join(cpue, by=c("sampleID", "caughtBy"))%>%
  mutate(nCaught=ifelse(is.na(nCaught), 0, nCaught))


```


code for processing mark recap data

```{r}
fish_samples<-dbTable("fish_samples", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(useSampleMarkRecap=="yes")

# ok, we want to do projects 37 and 38 separately. 37 used AF (anal fin) tags, 38 used PIT tags
fish_info<-dbTable("fish_info", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(sampleID%in%fish_samples$sampleID)%>%
  filter(otu=="largemouth_bass")

fish_data<-inner_join(fish_samples, fish_info, by="sampleID")%>%
  mutate(lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         clipRecapture=as.numeric(clipRecapture),
         clipRecapture=ifelse(is.na(clipRecapture),0,clipRecapture),
         tagged=ifelse(clipApply=="AF", 1, 0))

samples<-unique(fish_data$sampleID)

lakes<-dbTable("lakes", fpath=db.dir)

fish_samples<-data.frame(sampleID=unique(fish_data$sampleID))%>%
  mutate(method=str_split_fixed(sampleID, "_", 6)[,5],
         sampleDate=str_split_fixed(sampleID, "_", 4)[,3],
         sampleTime=str_split_fixed(sampleID, "_", 5)[,4],
         date_time=ymd_hm(paste(sampleDate, sampleTime, sep="_")),
         # adjust sampleDates for night electrofishing--if method==BE and sampleTime is in the evening before midnight, add one day to date.
         adjust=ifelse(method=="BE" & sampleTime<2359 & sampleTime>1200, 1, 0),
         adj_sampleDate=as.character(ymd(sampleDate)+days(1)),
         batchDate=ifelse(adjust==1, adj_sampleDate, as.character(ymd(sampleDate))),
         batchDate_method=paste(batchDate, method, sep="_"))

fish_pe<-left_join(fish_data, fish_samples[,c("sampleID","batchDate_method")], by="sampleID")%>%
  group_by(lakeID, batchDate_method)%>%
  summarize(markedNow=sum(tagged, na.rm=T),
            recapturedNow=sum(clipRecapture))%>%
  mutate(marked_cum=cumsum(markedNow),
         markedPrior=lag(marked_cum),
         markedPrior=ifelse(is.na(markedPrior), 0, markedPrior),
         allFishCaught=markedNow+recapturedNow)%>%
  ungroup()

# let's filter to lakes that had at least 1 recapture

recap_count<-fish_pe%>%
  group_by(lakeID)%>%
  summarize(nRecap=sum(recapturedNow))%>%
  arrange(desc(nRecap))%>%
  filter(nRecap>0)

recap_over_1<-filter(recap_count, nRecap>1)

# surface area for Found lake was missing. Got it from WI DNR (find a lake tool) and converted to hectares
lakes[lakes$lakeID=="FD",]$surfaceArea<-136.0

fish_pe_recap<-fish_pe%>%
  filter(lakeID%in%recap_count$lakeID)%>%
  mutate(CtMt=allFishCaught*markedPrior)%>%
  group_by(lakeID)%>%
  summarize(sumCtMt=sum(CtMt),
            sumRt=sum(recapturedNow))%>%
  ungroup()%>%
  left_join(lakes[,c("lakeID","surfaceArea")], by="lakeID")


fish_pe_for_table<-fish_pe%>%
  filter(lakeID%in%recap_count$lakeID)%>%
  mutate(CtMt=allFishCaught*markedPrior)%>%
  group_by(lakeID)%>%
  summarize(sumCtMt=sum(CtMt),
            sumRt=sum(recapturedNow),
            sumCaught=sum(allFishCaught),
            nSampleEvents=n())%>%
  ungroup()%>%
  left_join(lakes[,c("lakeID","surfaceArea")], by="lakeID")%>%
    dplyr::select(lakeID, surfaceArea, sumCaught, sumRt, nSampleEvents, sumCtMt)


```

```{r}
data.join<-full.data%>%
  filter(lakeID%in%fish_pe_recap$lakeID)%>%
  left_join(fish_pe_recap, by="lakeID")


lakeID<-data.frame(lakeID=fish_pe_recap$lakeID,
                   L=seq(1:13),
                   sumCtMt=fish_pe_recap$sumCtMt,
                   sumRt=fish_pe_recap$sumRt,
                   surfaceArea=fish_pe_recap$surfaceArea)

anglerID<-data.frame(caughtBy=unique(data.join$caughtBy),
                     A=seq(1:18))

dateID<-data.frame(date=unique(data.join$date),
                   D=seq(1:42))

data.indexed<-data.join%>%
  left_join(dateID, by="date")%>%
  left_join(anglerID, by="caughtBy")%>%
  left_join(lakeID, by="lakeID")%>%
  mutate(log_effort=log(effort))%>%
  rename("lmbCatch"=nCaught)

z_scores <- c(1.645, 0.674, 0, -0.674, -1.645)

data.list<-list(N=nrow(data.indexed),
                A=max(data.indexed$A),
                D=max(data.indexed$D),
                L=max(data.indexed$L),
                AA=data.indexed$A,
                DD=data.indexed$D,
                LL=data.indexed$L,
                lmbCatch=data.indexed$lmbCatch,
                log_effort=data.indexed$log_effort,
                sumCtMt=lakeID$sumCtMt,
                sumRt=lakeID$sumRt,
                surfaceArea=lakeID$surfaceArea,
                z_scores = z_scores,
                z_scores_long= rep(z_scores, each=21),
                z_scores_best_worst_angler = rep(c(z_scores[1], z_scores[1], z_scores[5], z_scores[5]), each=21),
                z_scores_best_worst_date = rep(c(z_scores[1], z_scores[5], z_scores[1], z_scores[5]), each=21),
                z_scores_medium_angler = rep(c(z_scores[2], z_scores[2], z_scores[4], z_scores[4]), each=21),
                z_scores_medium_date = rep(c(z_scores[2], z_scores[4], z_scores[2], z_scores[4]), each=21),
                log_popDensity_pred=log(seq(1, 201, by=10))
                )


```

Lake table--name, WBIC, number (L), location, surface area, n observations, n marks, n recaps

```{r}
lakeTable.fs<-read_csv(here("data","lakeTable.update.3.csv"))

units<-dbTable("units", fpath=db.dir, dbname=db)%>%
  filter(tableName=="LAKES" & colName=="surfaceArea") 
# yes, in hectares

bay<-projects<-dbTable("lakes", fpath=db.dir, dbname=db)%>%
  dplyr::select(lakeID, lakeName, surfaceArea, lat, long, WBIC)%>%
  filter(lakeID=="BA")


n.obs<-data.indexed%>%
  group_by(lakeID)%>%
  # note that multiple entries were sometimes listed per angler effort block, so nDates*nAnglers!=nObs
  summarize(nObs=n(),
            nDates=length(unique(date)),
            nAnglers=length(unique(caughtBy)))%>%
  left_join(lakeTable.fs[c("lakeID","lakeName","WBIC","lat","long")], by="lakeID")

bay.row<-c("BA",5,2,4,bay$lakeName, NA,  bay$lat, bay$long)

lake.table.n<-rbind.data.frame(n.obs[1,], bay.row, n.obs[3:13,])%>%
  left_join(lakeID[,c("lakeID", "L")], by="lakeID")%>%
  left_join(fish_pe_for_table, by="lakeID")%>%
  dplyr::select(lakeName, L, WBIC, lat, long, surfaceArea ,nObs, nDates, nAnglers, 
         sumCaught, sumRt, nSampleEvents, sumCtMt)%>%
  rename("nAnglingObs"=nObs,
         "nAnglingDates"=nDates,
         "totalCaught"=sumCaught,
         "totalRecaptured"=sumRt)
write.csv(lake.table.n, here("output_selected_model","tables","lake.table.csv"))
```
distance between lakes

```{r}
lake.dist<-lake.table.n%>%
  dplyr::select(lakeName, lat, long)%>%
  mutate(lake2=lakeName,
         lat2=lat,
         long2=long)

lake.rep<-rep(lake.table.n$lakeName, each=13)
lake.rep.2<-rep(lake.table.n$lakeName, 13)

lake.dist.long<-cbind.data.frame(lake.rep, lake.rep.2)
names(lake.dist.long)<-c("lakeName","lake2")

lake.dist.full<-left_join(lake.dist.long, lake.dist[,c("lakeName","lat","long")], by="lakeName")%>%
  left_join(lake.dist[,c("lake2","lat2","long2")], by="lake2")%>%
  mutate(across(lat:long2, as.numeric))

distances<-lake.dist.full%>%
  rowwise()%>%
  mutate(distance=spatialrisk::haversine(lat, long, lat2, long2),
         distance.km=distance/1000)%>%
  filter(distance.km!=0)

mean(distances$distance.km)
max(distances$distance.km)
min(distances$distance.km)
sd(distances$distance.km)

```

```{r}
catch<-ggplot()+
  geom_histogram(aes(x=data.list$lmbCatch), binwidth=1)+
  xlab("Bass catch per angler")+
  ylab("Count")+
  theme_bw()+
    theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16))

effort<-ggplot()+
  geom_histogram(aes(x=exp(data.list$log_effort)), binwidth=0.25)+
  xlab("Hours of fishing effort")+
    ylab("Count")+
  theme_bw()+
    theme(axis.title.y=element_blank(),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16))

plot_grid(catch, effort, labels=c("A","B"))
ggsave(here::here("output_selected_model","figures","catch.effort.histograms.png"),height=4,width=8)
```


```{r}
# set.seed(26)
# 
# # this model is the selected model that also generates posterior predictions
#  fit_gen<-stan(file=here("candidate_models","selected_model_angler_date_int_gen.stan"),
#                   data=data.list,
#                   control=list(stepsize=0.1, max_treedepth=15),
#                   chains=4,
#                   warmup=1000,
#                   iter=3000,
#                   cores=4,
#                   refresh=0)
# saveRDS(fit_gen, here("output_selected_model","fits","model_with_predictions.rds"))
# for use after model has been fit
fit_gen<-readRDS(here("output_selected_model","fits","model_with_predictions.rds"))

post_gen<-extract(fit_gen)

```

summary table
```{r}

fit.table<-rstan::summary(fit_gen, pars=c("beta","phi","sigma_q_a","sigma_q_d", "popDensity",
                               "log_q_a","log_q_d",
                               "log_q_mu","log_mu_q_a","log_mu_q_d","q_a_raw",
                         "q_d_raw","lp__"))

table.summary<-fit.table$summary
write.csv(table.summary, here::here("output_selected_model","tables","fit_angler_date_int_param_summary.csv"))
```


First thing is a nice set of plots showing the posteriors of beta, each sigma, the mean intercept, and the angler-, lake-, and date-specific intercepts

```{r}

 sigma_q_a<-(post_gen$sigma_q_a)
 sigma_q_d<-(post_gen$sigma_q_d)
 sigma.df<-data.frame(param=c(rep("sigma_q_a", length(sigma_q_a)),
                              rep("sigma_q_d", length(sigma_q_d))),
                      sd=c(sigma_q_a, sigma_q_d))
 log_q_a<-as.data.frame(post_gen$log_q_a)
 log_q_d<-as.data.frame(post_gen$log_q_d)
 
 names_a<-paste0("angler_", seq(1:18))
 names_d<-as.character(unique(data.indexed$date))

 names(log_q_a)<-names_a
 names(log_q_d)<-names_d
 

 
 angler_long<-log_q_a%>%
   pivot_longer(cols=everything(), names_to="angler", values_to="angler_effect")%>%
   mutate(angler=factor(angler, levels=c("angler_1","angler_2","angler_3","angler_4","angler_5","angler_6","angler_7","angler_8","angler_9","angler_10","angler_11","angler_12","angler_13","angler_14","angler_15","angler_16","angler_17","angler_18")))
 
 date_long<-log_q_d%>%
   pivot_longer(cols=everything(), names_to="date", values_to="date_effect")%>%
   mutate(date=as.factor(as.numeric(date)))
   


```

density plot figures 

fun color palettes

```{r}
library(scales)
futurama<-pal_futurama("planetexpress")(12)
simpsons<-pal_simpsons("springfield")(12)

```

compare posteriors with priors

```{r}
popDensity.prior<-post_gen$prior_t_popDensity[post_gen$prior_t_popDensity>=0]
half.t.prior<-post_gen$prior_t_other[post_gen$prior_t_other>=0]
phi.prior<-post_gen$prior_phi
prior.sigma<-half.t.prior

beta.prior<-half.t.prior
sigma.q.priors<-half.t.prior

post<-post_gen

popDensity.post<-post$popDensity
beta.post<-post$beta
phi.post<-post$phi
sigma.q.a.post<-post$sigma_q_a
sigma.q.d.post<-post$sigma_q_d

popDensity.post.df<-as.data.frame(popDensity.post)
names(popDensity.post.df)<-paste0("lake_", seq(1:13))

popDensity.plot<-popDensity.post.df%>%
  pivot_longer(cols=everything(), names_to="lake", values_to="popDensity")%>%
  mutate(lake=factor(lake, levels=c("lake_1","lake_2","lake_3","lake_4","lake_5","lake_6","lake_7","lake_8","lake_9","lake_10",
                                    "lake_11","lake_12","lake_13")))

ggplot()+
  geom_density(data=popDensity.plot, aes(x=popDensity, fill=lake), alpha=0.5)+
    geom_density(aes(x=popDensity.prior), fill="gray", alpha=0.7)+
  xlim(0,200)+
  xlab("Population density (1/ha)")+
   ylab(expression(paste("Probability density p(", "Population density", "|Catch)")))+
  theme_bw()


ggsave(here("output_selected_model", "figures", "popDensity_prior_check.png"))
```


```{r}
ggplot()+
  geom_density(aes(x=beta.prior), bounds=c(0, Inf), fill="gray")+
  geom_density(aes(x=beta.post), fill="lightblue")+
  xlim(0,10)+
     ylab(expression(paste("Probability density p(", beta, "|Catch)")))+
  xlab(expression(beta))+
  theme_bw()
  ggsave(here("output_selected_model", "figures",  "beta_prior_check.png"))

```

```{r}
ggplot()+
  geom_density(aes(x=phi.prior), fill="gray",  bounds=c(0, Inf))+
  geom_density(aes(x=phi.post), fill="lightblue")+
  ylab(expression(paste("Probability density p(", phi, "|Catch)")))+
  xlab(expression(phi))+
  xlim(0,10)+
  theme_bw()
ggsave(here("output_selected_model", "figures", "phi_prior_check.png"))

```

```{r}
sigma.check<-data.frame(group=c(rep("prior", length(sigma.q.priors)), rep("angler", 8000), rep("date", 8000)),
                        sigma.q=c(sigma.q.priors, sigma.q.a.post, sigma.q.d.post))

ggplot(sigma.check)+
  geom_density(aes(x=sigma.check$sigma.q, fill=group), alpha=0.5, bounds=c(0, Inf))+
  scale_fill_manual("Effect",values=c("lightpink","lightyellow","gray"))+
  xlim(0,10)+
   ylab(expression(paste("Probability density p(", sigma["q"], "|Catch)")))+
  xlab(expression(sigma["q"]))+
  theme_bw()
ggsave(here("output_selected_model", "figures","sigma_prior_check.png"))

```

```{r}
sigma.2.angler<-post_gen$sigma_2_post_angler
hist(sigma.2.angler)
```



```{r}
# link.pred<-post_gen$link_predictions
# sigma.2.link.pred<-post_gen$sigma_2_link_pred

# pred<-post_gen$posterior_pred_check
# pred_fixed<-post_gen$posterior_pred_fixed
# pred_angler<-post_gen$posterior_pred_angler
# pred_date<-post_gen$posterior_pred_date
# pred_nb_only<-post_gen$posterior_pred_nb_only

sigma.2.pred.df<-data.frame(param=c(rep("Full model", 8000), rep("Angler effects", 8000), rep("Date effects",8000),
                                    rep("Population density effect", 8000), rep("No covariates", 8000)),
                            sigma2=c(post_gen$sigma_2_post_full, post_gen$sigma_2_post_angler, post_gen$sigma_2_post_date,
                                    post_gen$sigma_2_post_fixed, post_gen$sigma_2_post_nb_only))%>%

  mutate(param=factor(param, levels=c("No covariates","Angler effects","Date effects","Population density effect","Full model")))

sigma.2.pred.wide<-data.frame(sigma2_full=post_gen$sigma_2_post_full,
                              sigma2_angler=post_gen$sigma_2_post_angler-post_gen$sigma_post_nb_only,
                              sigma2_date=post_gen$sigma_2_post_date-post_gen$sigma_post_nb_only,
                              sigma2_PE=post_gen$sigma_2_post_fixed-post_gen$sigma_post_nb_only,
                              sigma2_random=post_gen$sigma_2_post_nb_only)%>%
  mutate(sigma2_sum=sigma2_angler+sigma2_date+sigma2_PE+sigma2_random,
         prop_PE=sigma2_PE/sigma2_sum,
         prop_angler=sigma2_angler/sigma2_sum,
         prop_date=sigma2_date/sigma2_sum,
         prop_random=sigma2_random/sigma2_sum,
         )

hist(sigma.2.pred.wide$prop_angler)
hist(sigma.2.pred.wide$prop_date)
hist(sigma.2.pred.wide$prop_PE)
hist(sigma.2.pred.wide$prop_random)

hist(sigma.2.pred.wide$sigma2_full)
hist(sigma.2.pred.wide$sigma2_sum)
```
I think that now I want to fit a beta distribution to each of these distributios of proportion variance

```{r}
angler.prop<-fitdist(sigma.2.pred.wide$prop_angler, "beta")
mean(sigma.2.pred.wide$prop_angler)
sd(sigma.2.pred.wide$prop_angler)

alpha<-angler.prop$estimate[1]
beta<-angler.prop$estimate[2]

angler.prop$estimate[1]/(angler.prop$estimate[1]+angler.prop$estimate[2])
sqrt((alpha*beta)/((alpha+beta)^2*(alpha+beta+1)))

plot(angler.prop)
```


```{r}
ggplot(sigma.2.pred.wide)+
  geom_point(aes(x=sigma2_angler, y=sigma2_date))

ggplot(sigma.2.pred.wide)+
  geom_point(aes(x=prop_angler, y=prop_date))

cor.sigma2<-select(sigma.2.pred.wide, sigma2_full, sigma2_angler, sigma2_date, sigma2_PE)

cor.prop<-select(sigma.2.pred.wide, prop_PE:prop_random)

chart.Correlation(cor.sigma2)

```

```{r}
chart.Correlation(cor.prop)

```

```{r}

# results are abouat the same using median instead of mean

# sigma.2.df.median<-sigma.2.pred.df%>%
#   group_by(param)%>%
#   summarize(med.var=median(sigma2))%>%
#   ungroup()%>%
#   mutate(random.var=rep(median(post_gen$sigma_2_post_nb_only)),
#          med.var.sub=ifelse(param=="No covariates", med.var, med.var-random.var),
#          full.mod.var=rep(median(post_gen$sigma_2_post_full)),
#          prop.var=med.var.sub/full.mod.var)


sigma.2.df.sum<-sigma.2.pred.df%>%
  group_by(param)%>%
  summarize(mean.var=mean(sigma2),
            var.of.var=sd(sigma2)^2)%>%
  ungroup()%>%
  mutate(mean.random.var=rep(mean(post_gen$sigma_2_post_nb_only)),
         var.random.var=rep(sd(post_gen$sigma_2_post_nb_only)^2),
         mean.var.sub=ifelse(param=="No covariates", mean.var, mean.var-mean.random.var),
         # propagating uncorrelated variance, so this is variance of (submodel) variance (sum of variances)
         # variance of the proportion variance is approximated by a first order taylor expansion
         # https://www.stat.cmu.edu/~hseltman/files/ratio.pdf 
         var.var.sub=var.random.var+var.of.var,
         full.mod.var=rep(mean(post_gen$sigma_2_post_full)),
         var.full.mod.var=rep(sd(post_gen$sigma_2_post_full)^2),
         prop.var=mean.var.sub/full.mod.var,
         var.prop.var=(mean.var.sub^2/full.mod.var^2)*((var.var.sub/mean.var.sub^2)+(var.full.mod.var/full.mod.var^2)),
         sd.prop.var=sqrt(var.prop.var))
# now use the variance to estimate credible intervals of a beta distribution I guess

alpha.beta<-sigma.2.df.sum%>%
  select(param, prop.var, var.prop.var)%>%
  mutate(alpha=(((1-prop.var)/var.prop.var)-(1/prop.var))*prop.var^2,
         beta=alpha*((1/prop.var)-1))

sigma.2.pred.df.lines<-sigma.2.pred.df%>%
  left_join(sigma.2.df.sum, by="param")


sigma.2.density.legend<-ggplot(sigma.2.pred.df.lines)+
  # density of variance
  geom_density(aes(x=sigma2, fill=param))+
  # mean variance for each density plot
  geom_vline(aes(xintercept = mean.var), linetype="dotted")+
  scale_fill_manual(values=futurama[c(3, 1, 4, 8, 2)], "Sub-models")+
  facet_wrap(.~param, ncol=1)+
  xlab(expression(sigma[hat("catch")]^2))+
  xlim(0,75)+
  ylab(expression(paste("Probability density p(", sigma[hat("catch")]^2, "|Catch)")))+
  theme_bw()+
    theme(legend.title=element_text(size=14),
        legend.text=element_text(size=12),
        axis.title.y=element_text(size=14),
        axis.title.x=element_text(size=16), 
        strip.text.x=element_blank())
legend<-get_legend(sigma.2.density.legend)

sigma.2.density<-ggplot(sigma.2.pred.df.lines)+
  # density of variance
  geom_density(aes(x=sigma2, fill=param))+
  # mean variance for each density plot
  geom_vline(aes(xintercept = mean.var), linetype="dotted")+
  scale_fill_manual(values=futurama[c(3, 1, 4, 8, 2)], "Sub-models")+
  facet_wrap(.~param, ncol=1)+
  xlab(expression(sigma[hat("catch")]^2))+
  xlim(0,75)+
  ylab(expression(paste("Probability density p(", sigma[hat("catch")]^2, "|Catch)")))+
  theme_bw()+
    theme(legend.title=element_text(size=14),
        legend.text=element_text(size=12),
        axis.title.y=element_text(size=14),
        axis.title.x=element_text(size=16), 
        #strip.text.x=element_blank(),
        legend.position="none")


ggsave(here::here("output_selected_model","figures","submodel.sigma.density.png"), height=8, width=8)

  
  


sigma.2.density

```

Can I make a stacked bar plot?

```{r}
sigma.2.df.sum.bar<-sigma.2.df.sum%>%
  filter(param!="Full model")%>%
    mutate(param=factor(param, levels=c("No covariates","Angler effects","Date effects","Population density effect")))%>%
    arrange(desc(param))%>%
    mutate(group=rep(as.factor(1)),
           position=cumsum(prop.var)-0.5*prop.var,
           note=as.character(round(prop.var, digits=2)),
           note=str_pad(note, width=4,side="right", pad="0"))%>%
    arrange(param)


position<-sigma.2.df.sum.bar$position
note<-sigma.2.df.sum.bar$note

bar.full<-ggplot(sigma.2.df.sum.bar)+
  geom_bar(aes(x=group, y=prop.var, fill=param), stat="identity", position="stack")+
  scale_fill_manual(values=futurama[c(3,1,4,8)], "Model predictions")+
  annotate("text", x=1, y=position, label=note)+
  ylab("Mean predicted proportion of variance")+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        legend.title=element_text(size=14),
        legend.text=element_text(size=12),
        axis.title.y=element_text(size=14))


bar.plot<-ggplot(sigma.2.df.sum.bar)+
  geom_bar(aes(x=group, y=prop.var, fill=param), stat="identity", position="stack")+
  scale_fill_manual(values=futurama[c(3,1,4,8)], "Model predictions")+
  annotate("text", x=1, y=position, label=note)+
  ylab("Mean predicted proportion of variance")+
  scale_y_continuous(limits=c(0,1), expand=c(0,0))+
  theme_classic()+
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        legend.position="none",
        axis.title.y=element_text(size=14))
  bar.plot
```

arranging plot
```{r}
plot_grid(plot_grid(bar.plot, legend, ncol=1, rel_heights=c(0.75, 0.25)), sigma.2.density, ncol=2, rel_widths=c(0.3, 0.7))
ggsave(here("output_selected_model","figures","bar.density.png"), height=8, width=6)
```
```{r}
plot_grid(plot_grid(bar.plot, NULL, ncol=1, rel_heights=c(0.75, 0.25)), sigma.2.density, ncol=2, rel_widths=c(0.3, 0.7), labels=c("A","B"))


ggsave(here("output_selected_model","figures","alt.bar.density.png"), height=8, width=6)

```


just the random effects
```{r}
 sigma.random.plot<-ggplot(sigma.df)+
   geom_density(aes(x=sd, fill=param), alpha=0.7)+
   scale_fill_manual(values=futurama[c(1,4)], name="Parameters", labels=expression(sigma[a], sigma[d]))+
   xlim(0,2)+
   ylab(expression(paste("Probability density p(", sigma["a,d"], "|catch)")))+
   xlab(expression(sigma["a,d"]))+
   theme_bw()+
   theme(legend.text=element_text(size=16),
         axis.title.y=element_text(size=14),
         axis.title.x=element_text(size=14))
 sigma.random.plot
ggsave(here::here("output_selected_model","figures","random.effects.sigma.png"), height=4, width=6)
```




```{r}
obs<-data.list$lmbCatch
pred<-post_gen$posterior_pred_check[1,]

ggplot()+
  geom_point(aes(x=obs, y=pred))+
  geom_abline(slope=1, intercept=0, linetype="dashed")+
  ylim(0,40)+
  xlim(0,40)+
  theme_bw()
```



```{r}
angler_long_plot<-angler_long%>%
  group_by(angler)%>%
  summarize(mean=mean(angler_effect), 
            sd=sd(angler_effect),
            upper95=mean+1.96*sd,
            lower95=mean-1.96*sd)%>%
  ungroup()%>%
  mutate(angler=as.factor(as.numeric(str_replace(angler, "angler_", ""))))

angler<-ggplot(angler_long_plot)+
  geom_point(aes(x=mean, y=angler))+
  geom_errorbarh(aes(y=angler, xmin=lower95, xmax=upper95))+
  ylab("Angler observed")+
  xlab(expression(paste("Angler skill effect (ln", q["a"], ")")))+
  theme_bw()

  
  angler
  ggsave(here("output_selected_model","figures","angler.effects.png"), height=4, width=6)
```

```{r}
date_long_plot<-date_long%>%
  group_by(date)%>%
  summarize(mean=mean(date_effect), 
            sd=sd(date_effect),
            upper95=mean+1.96*sd,
            lower95=mean-1.96*sd)%>%
  ungroup()%>%
  mutate(date=as.factor(ymd(date)))

date<-ggplot(date_long_plot)+
  geom_point(aes(x=mean, y=date))+
  geom_errorbarh(aes(y=date, xmin=lower95, xmax=upper95))+
  ylab("Date observed")+
  xlab(expression(paste("Daily conditions effect (ln", q["d"], ")")))+
  theme_bw()

  
  date
  ggsave(here("output_selected_model","figures","date.effects.png"), height=6, width=6)

```

Lake effect
Now predictions of mean catch for each angler--are violin plots really appropriate since they're discrete predictions?

```{r}
angler.pred<-as.data.frame(post_gen$predict_angler_catch)

names(angler.pred)<-paste0("angler_", seq(1:18))

angler.pred.long<-angler.pred%>%
  pivot_longer(cols=everything(), names_to="angler", values_to="catch")%>%
  mutate(angler=as.factor(as.numeric(str_replace(angler, "angler_", ""))))

ggplot(angler.pred.long)+
  geom_violin(aes(x=angler, y=catch), fill=futurama[7])+
  theme_bw()+
  theme(legend.position="none")+
  coord_flip()+
  xlab("Angler observed")+
  ylab("Predicted mean catch")
ggsave(here::here("output_selected_model","figures","angler.mean.pred.catch.png"), height=6, width=4)
```
That's not very useful for readers; instead do quantiles

```{r}
quant.catch.df<-as.data.frame(post_gen$predict_quantile_catch)

names(quant.catch.df)<-c("95th", "75th", "50th", "25th", "5th")

quant.catch.long<-quant.catch.df%>%
  pivot_longer(cols=everything(), names_to="Angler skill", values_to="Mean catch")%>%
  mutate(`Angler skill`=factor(`Angler skill`, levels=c("5th", "25th", "50th", "75th", "95th")))

quant.catch.sum<-quant.catch.long%>%
  group_by(`Angler skill`)%>%
  summarize(mean=mean(`Mean catch`),
            median=median(`Mean catch`),
            sd=sd(`Mean catch`),
            upper=mean+1.96*sd,
            lower=mean-1.96*sd)

angler.violin<-ggplot(quant.catch.long)+
  geom_violin(aes(x=`Angler skill`, y=`Mean catch`), fill=futurama[1], adjust=2)+
  geom_point(data=quant.catch.sum, aes(x=`Angler skill`, y=mean), size=3)+
  geom_point(data=quant.catch.sum, aes(x=`Angler skill`, y=median), size=3, color="gray")+
  coord_flip()+
  xlab(expression(paste("Angler skill percentile (ln", "q"["a"], ")")))+
  ylab("Predicted mean catch")+
  theme_bw()+
  theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16))
angler.violin
ggsave(here("output_selected_model","figures", "percentile.catch.violin.png"), height=4, width=6)
```

Finally for these quantiles of anglers across a range of population densities

Showing here: there is a lot of unexplained variation, yes. The mean effect of angler skill and daily conditions, however, is still in the range that's noticeable

55 rows of predictions
```{r}
popDensity<-rep(seq(1,201, by=10), 5)
percentile<-rep(c("95%","75%","50%","25%","5%"), each=21)


angler.pred.pop<-post_gen$predict_quantile_angler_catch_popDens

catch.angler.df<-data.frame(popDensity=popDensity,
                            percentile=factor(percentile, levels=rev(c("95%","75%","50%","25%","5%"))),
                            meanCatch=colMeans(angler.pred.pop)
                            )

pred.quantiles.angler<-apply(angler.pred.pop, 2, quantile, probs=c(0.025, 0.125,0.25, 0.75, 0.875,0.975))

pred.quant.angler.df<-as.data.frame(t(pred.quantiles.angler), names=rownames(pred.quantiles.angler))

angler.plot<-cbind.data.frame(catch.angler.df, pred.quant.angler.df)

gradient.a<-c("#ffdce2","#ffced1","#ffafa6","#ff8d6b","#FF6F00FF")

angler.pop<-ggplot(angler.plot)+
  geom_line(aes(x=popDensity, y=meanCatch, color=percentile), linewidth=2)+
  geom_ribbon(aes(x=popDensity, ymin=`25%`, ymax=`75%`, group=percentile), alpha=0.1)+
  scale_color_manual(values=gradient.a)+
  guides(color=guide_legend(title=expression(paste("Angler skill\neffect percentile"))))+
  xlab("Population density (1/ha)")+
  ylab("Predicted mean catch")+
  theme_bw()+
    theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16))
angler.pop
ggsave(here("output_selected_model","figures","angler.effect.popDensity.png"), height=4, width=6)
```
yeah, CIs don't show up well, but I think I can do them for the best-worst comparison

Next daily conditions

```{r}
quant.date.catch.df<-as.data.frame(post_gen$predict_quantile_date_catch)

names(quant.date.catch.df)<-c("95th", "75th", "50th", "25th", "5th")

quant.date.catch.long<-quant.date.catch.df%>%
  pivot_longer(cols=everything(), names_to="Day effect", values_to="Mean catch")%>%
  mutate(`Day effect`=factor(`Day effect`, levels=c("5th", "25th", "50th", "75th", "95th")))

quant.date.catch.sum<-quant.date.catch.long%>%
  group_by(`Day effect`)%>%
  summarize(mean=mean(`Mean catch`),
            median=median(`Mean catch`),
            sd=sd(`Mean catch`),
            upper=mean+1.96*sd,
            lower=mean-1.96*sd)

date.violin<-ggplot(quant.date.catch.long)+
  geom_violin(aes(x=`Day effect`, y=`Mean catch`), fill="#8A4198FF", adjust=2)+
  geom_point(data=quant.date.catch.sum, aes(x=`Day effect`, y=mean), size=3)+
  geom_point(data=quant.date.catch.sum, aes(x=`Day effect`, y=median), size=3, color="gray")+
  coord_flip()+
  xlab(expression(paste("Daily effect percentile (ln", "q"["d"], ")")))+
  ylab("Predicted mean catch")+
  theme_bw()+
  theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16))
date.violin
ggsave(here("output_selected_model","figures", "percentile.day.catch.violin.png"), height=4, width=6)

```


```{r}
popDensity<-rep(seq(1,201, by=10), 5)
percentile<-rep(c("95%","75%","50%","25%","5%"), each=21)


date.pred.pop<-post_gen$predict_quantile_date_catch_popDens

catch.date.df<-data.frame(popDensity=popDensity,
                            percentile=factor(percentile, levels=rev(c("95%","75%","50%","25%","5%"))),
                            meanCatch=colMeans(date.pred.pop))

pred.quantiles.date<-apply(date.pred.pop, 2, quantile, probs=c(0.025, 0.125,0.25, 0.75, 0.875,0.975))


pred.quant.date.df<-as.data.frame(t(pred.quantiles.date), names=rownames(pred.quantiles.date))

date.plot<-cbind.data.frame(catch.date.df, pred.quant.date.df)


gradient.d<-c("#efd2dd","#d9a6c3","#bf7caf","#9e55a0","#8A4198FF")

date.pop<-ggplot(date.plot)+
  geom_line(aes(x=popDensity, y=meanCatch, color=percentile), linewidth=2)+
  geom_ribbon(aes(x=popDensity, ymin=`25%`, ymax=`75%`, group=percentile), alpha=0.1)+
  scale_color_manual(values=gradient.d)+
  guides(color=guide_legend(title=expression(paste("Daily conditions\neffect percentile"))))+
  xlab("Population density (1/ha)")+
  ylab("Predicted mean catch")+
  theme_bw()+
    theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16))
date.pop
ggsave(here("output_selected_model","figures","date.effect.popDensity.png"), height=4, width=6)


```
As we'd expect from the sigma_d distribution, it's very similar

```{r}
library(cowplot)

plot_grid(angler.violin, angler.pop, rel_widths=c(1, 1.3), labels=c("A","B"))
ggsave(here("output_selected_model","figures","angler.effect.plot.png"), height=4, width=8)
```

```{r}
plot_grid(date.violin, date.pop, rel_widths=c(1, 1.3), labels=c("A","B"))
ggsave(here("output_selected_model","figures","date.effect.plot.png"), height=4, width=8)

```
justcombine?

```{r}
plot_grid(angler.violin, angler.pop, date.violin, date.pop, nrow=2,rel_widths=c(1, 1.3, 1, 1.3), labels=c("A","B","C","D"))
ggsave(here("output_selected_model","figures","effect.plots.all.png"), height=8, width=8)

```


Effects together? highest percentiles and lowest percentiles


```{r}
show_col(simpsons)
c( "#F05C3BFF", "#197EC0FF")
```


```{r}
quantiles<-c("95%", "5%")


best.worst.df<-data.frame(pred.catch=colMeans(post_gen$predict_best_worst),
                          pop.density=rep(seq(1, 201, by=10), 4),
                          quant.angler=factor(rep(quantiles, each=42), levels=c("5%","95%")),
                          quant.date=factor(rep(quantiles, each=21), levels=c("5%","95%")))%>%
  mutate(group=ifelse(quant.angler=="95%" & quant.date=="95%", "High skill,\ngood conditions",
                      ifelse(quant.angler=="95%" & quant.date=="5%", "High skill,\npoor conditions",
                             ifelse(quant.angler=="5%" & quant.date=="95%", "Low skill,\ngood conditions",
                                    ifelse(quant.angler=="5%" & quant.date=="5%", "Low skill,\npoor conditions", "error")))),
         facet=ifelse(quant.angler=="95%", "High skill (95th percentile)", "Low skill (5th percentile)"),
         legend=ifelse(quant.date=="95%", "Good (95th percentile)", "Poor (5th percentile)"))

best.worst.ci<-t(apply(post_gen$predict_best_worst, 2, quantile, probs=c(0.025, 0.125,0.25, 0.75, 0.875,0.975)))

best.worst.plot<-cbind.data.frame(best.worst.df, best.worst.ci)

ggplot(best.worst.plot)+
  geom_line(aes(x=pop.density, y=pred.catch, color=legend), linewidth=2)+
  geom_ribbon(aes(x=pop.density, ymin=`25%`, ymax=`75%`, group=legend), alpha=0.1)+
  scale_color_manual(values=c( "#F05C3BFF", "#197EC0FF"))+
  xlim(0,150)+
  facet_grid(.~facet)+
  guides(color=guide_legend(title="Daily conditions"))+
  xlab("Population density (1/ha)")+
  ylab("Predicted mean catch")+
  theme_bw()+
    theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16),
        strip.text.x=element_text(size=11),
        legend.text=element_text(size=11),
        legend.title=element_text(size=12))
ggsave(here("output_selected_model","figures","best.worst.comparison.png"), height=4, width=8)

```

Ah, right, it's a multiplicative effect of angler skill and daily conditions. 

I'd like a version with 75-25 because these extremes are wild. 

```{r}
quantiles<-c("75%", "25%")


medium.df<-data.frame(pred.catch=colMeans(post_gen$predict_medium),
                          pop.density=rep(seq(1, 201, by=10), 4),
                          quant.angler=factor(rep(quantiles, each=42), levels=c("25%","75%")),
                          quant.date=factor(rep(quantiles, each=21), levels=c("25%","75%")))%>%
  mutate(facet=ifelse(quant.angler=="75%", "Higher skill (75th percentile)", "Lower skill (25th percentile)"),
         legend=ifelse(quant.date=="75%", "Good (75th percentile)", "Poor (25th percentile)"))

medium.ci<-t(apply(post_gen$predict_medium, 2, quantile, probs=c(0.025, 0.125,0.25, 0.75, 0.875,0.975)))

medium.plot<-cbind.data.frame(medium.df, medium.ci)

ggplot(medium.plot)+
  geom_line(aes(x=pop.density, y=pred.catch, color=legend), linewidth=2)+
  geom_ribbon(aes(x=pop.density, ymin=`25%`, ymax=`75%`, group=legend), alpha=0.2)+
  scale_color_manual(values=c( "#F05C3BFF", "#197EC0FF"))+
  xlim(0,150)+
  facet_grid(.~facet)+
  guides(color=guide_legend(title="Daily conditions"))+
  xlab("Population density (1/ha)")+
  ylab("Predicted mean catch")+
  theme_bw()+
    theme(axis.title.y=element_text(size=16),
        axis.text.y=element_text(size=12),
        axis.text.x=element_text(size=12),
        axis.title.x=element_text(size=16),
        strip.text.x=element_text(size=11),
        legend.text=element_text(size=11),
        legend.title=element_text(size=12))
ggsave(here("output_selected_model","figures","medium.comparison.png"), height=4, width=8)

```

