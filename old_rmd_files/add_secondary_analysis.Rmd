---
title: "add_secondary_analysis"
output: html_document
date: "2024-07-01"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, here, lubridate, lme4, loo, rstan, shinystan, truncnorm, MFEUtilities, RColorBrewer, cowplot, lavaan, lunar, PerformanceAnalytics)
```

Pull raw data from MFE database

Looking again at the metadata, I may have made an error on effort--it's effort in angler-hours, and I don't know if I divided it by nAnglers to get effort per angler

```{r}
rm(list=ls())

# raw catch data
wd<-getwd()
db.dir<-paste0(wd, "/MFEdb/")
db<-"MFEdb_20220405.db"

dbTableList(db.dir, db)

lakes<-dbTable("lakes", fpath=db.dir, dbname=db)
#crew<-dbTable("crew", fpath=db.dir, dbname=db)%>%
#  filter(year%in%c("2018","2019"))
#write.csv(crew, "crew.csv")

# lake data

lakes.key<-lakes%>%
  dplyr::select(lakeID, lakeName, lat, long, WBIC, surfaceArea)
# Found lake missing surface area--135.97 ha
lakes.key[lakes.key$lakeID=="FD","surfaceArea"]<-135.97


projects<-dbTable("projects", fpath=db.dir, dbname=db)

fishSamples<-dbTable("fish_samples", fpath=db.dir, dbname=db)%>%
  filter(projectID%in%c("37") & gear=="AN")%>%
  mutate(nAnglers=as.numeric(nAnglers),
    effort=effort/nAnglers)

fishInfo<-dbTable("fish_info", fpath=db.dir, dbname=db)%>%
  filter(sampleID%in%fishSamples$sampleID)%>%
  filter(str_length(caughtBy)<4)%>%
  mutate(caughtBy=str_trim(caughtBy))%>%
  filter(otu=="largemouth_bass")%>%
  dplyr::select(projectID:caughtBy, comments)%>%
  # join fishing effort
  left_join(fishSamples[,c("lakeID","sampleID","dayOfYear","dateSample","dateTimeSample","crew","effort","effortUnits","nAnglers")], by="sampleID")

# catch rates for each angler trip, correcting for some ambiguous initials first

ALK.lake.date<-c("LV_20190608",
                 "SM_20190615",
                 "WN_20190617",
                 "BY_20190622")

AMK.lake.date<-c("DS_20190613",
                 "BOT_20190615",
                 "SM_20190621",
                 "BOT_20190624",
                 "NH_20190713")

long.crew<-fishSamples%>%
  group_by(sampleID)%>%
  summarize(crew=unique(crew),
            effort=unique(effort))%>%
  # split crew into columns and then pivot longer
  separate("crew", paste("angler", 1:3, sep="_"), sep=", ", extra="drop")%>%
  pivot_longer(cols=angler_1:angler_3, names_to="angler_num", values_to="caughtBy", values_drop_na=T)%>%
  mutate(caughtBy=ifelse(caughtBy=="CMI","CI", caughtBy))%>%
  mutate(date=str_split_fixed(sampleID, "_", 4)[,3],
         lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         lakeID_date=paste(lakeID, date, sep="_"))%>%
  mutate(caughtBy=ifelse(lakeID_date%in%AMK.lake.date, "AMK",
                         ifelse(lakeID_date%in%ALK.lake.date, "ALK", caughtBy)))
  
 #long.crew$date<-NULL
 #long.crew$lakeID<-NULL
 #long.crew$lakeID_date<-NULL
 
 
 all.data<-fishInfo%>%
  mutate(year=year(dateSample))%>%
  left_join(lakes.key, by="lakeID")
  

  
# now get catch rates from angling data and left join to long.crew. empty values can then be replaced with 0

cpue<-all.data%>%
  group_by(sampleID, caughtBy)%>%
  summarize(nCaught=n())



full.data<-long.crew%>%
  left_join(cpue, by=c("sampleID", "caughtBy"))%>%
  mutate(nCaught=ifelse(is.na(nCaught), 0, nCaught))



# join on mark recap data (sumCtRt and sumRt) and surface area

```


code for processing mark recap data

```{r}
fish_samples<-dbTable("fish_samples", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(useSampleMarkRecap=="yes")

# ok, we want to do projects 37 and 38 separately. 37 used AF (anal fin) tags, 38 used PIT tags
fish_info<-dbTable("fish_info", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(sampleID%in%fish_samples$sampleID)%>%
  filter(otu=="largemouth_bass")

fish_data<-inner_join(fish_samples, fish_info, by="sampleID")%>%
  mutate(lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         clipRecapture=as.numeric(clipRecapture),
         clipRecapture=ifelse(is.na(clipRecapture),0,clipRecapture),
         tagged=ifelse(clipApply=="AF", 1, 0))

samples<-unique(fish_data$sampleID)

lakes<-dbTable("lakes", fpath=db.dir)

fish_samples<-data.frame(sampleID=unique(fish_data$sampleID))%>%
  mutate(method=str_split_fixed(sampleID, "_", 6)[,5],
         sampleDate=str_split_fixed(sampleID, "_", 4)[,3],
         sampleTime=str_split_fixed(sampleID, "_", 5)[,4],
         date_time=ymd_hm(paste(sampleDate, sampleTime, sep="_")),
         # adjust sampleDates for night electrofishing--if method==BE and sampleTime is in the evening before midnight, add one day to date.
         adjust=ifelse(method=="BE" & sampleTime<2359 & sampleTime>1200, 1, 0),
         adj_sampleDate=as.character(ymd(sampleDate)+days(1)),
         batchDate=ifelse(adjust==1, adj_sampleDate, as.character(ymd(sampleDate))),
         batchDate_method=paste(batchDate, method, sep="_"))

fish_pe<-left_join(fish_data, fish_samples[,c("sampleID","batchDate_method")], by="sampleID")%>%
  group_by(lakeID, batchDate_method)%>%
  summarize(markedNow=sum(tagged, na.rm=T),
            recapturedNow=sum(clipRecapture))%>%
  mutate(marked_cum=cumsum(markedNow),
         markedPrior=lag(marked_cum),
         markedPrior=ifelse(is.na(markedPrior), 0, markedPrior),
         allFishCaught=markedNow+recapturedNow)%>%
  ungroup()

# let's filter to lakes that had at least 1 recapture

recap_count<-fish_pe%>%
  group_by(lakeID)%>%
  summarize(nRecap=sum(recapturedNow))%>%
  arrange(desc(nRecap))%>%
  filter(nRecap>0)

recap_over_1<-filter(recap_count, nRecap>1)

# surface area for Found lake was missing. Got it from WI DNR (find a lake tool) and converted to hectares
lakes[lakes$lakeID=="FD",]$surfaceArea<-136.0

fish_pe_recap<-fish_pe%>%
  filter(lakeID%in%recap_count$lakeID)%>%
  mutate(CtMt=allFishCaught*markedPrior)%>%
  group_by(lakeID)%>%
  summarize(sumCtMt=sum(CtMt),
            sumRt=sum(recapturedNow))%>%
  ungroup()%>%
  left_join(lakes[,c("lakeID","surfaceArea")], by="lakeID")

```
Now join those datasets and index the unique lakeIDs and caughtBy initials

```{r}
data.join<-full.data%>%
  filter(lakeID%in%fish_pe_recap$lakeID)%>%
  left_join(fish_pe_recap, by="lakeID")%>%
  mutate(date=ymd(date))


lakeID<-data.frame(lakeID=fish_pe_recap$lakeID,
                   L=seq(1:13),
                   sumCtMt=fish_pe_recap$sumCtMt,
                   sumRt=fish_pe_recap$sumRt,
                   surfaceArea=fish_pe_recap$surfaceArea)

anglerID<-data.frame(caughtBy=unique(data.join$caughtBy),
                     A=seq(1:18))

dateID<-data.frame(date=unique(data.join$date),
                   D=seq(1:42))

data.indexed<-data.join%>%
  left_join(dateID, by="date")%>%
  left_join(anglerID, by="caughtBy")%>%
  left_join(lakeID, by="lakeID")%>%
  mutate(log_effort=log(effort))%>%
  rename("lmbCatch"=nCaught)

# make some prediction data for output

lakeID_pred = rep(lakeID$L, 18)
anglerID_pred = rep(anglerID$A, each=13)
dateID_pred = rep(17, 234)
```

Adding weather and (incomplete) angler data for secondary analysis
```{r}
anglerData<-read_csv(here::here("data","angler_secondary_data_manual_clean.csv"))
# why are the column names weird? oh well
# oops duplicates that's why
#names(anglerData)<-str_replace_all(names(anglerData), "\\.\\.\\.\\d+", "")

likert.key<-c("Strongly disagree"=1,
              "Somewhat disagree"=2,
              "Neither agree nor disagree" =3,
              "Somewhat agree"=4,
              "Strongly agree"=5)

cfa.mod<-'centrality= ~lifeRevolves+mostEnjoyable+noTime+nothingElse'

anglerData_mod<-anglerData%>%
  mutate(across(lifeRevolves:specialGear, ~recode(.x, !!!likert.key)),
         daysFishedPast_sc=scale(daysFishedPast, center=T, scale=T))

cfa.fit<-cfa(cfa.mod, data=anglerData_mod)
summary(cfa.fit, fit.measures=TRUE)

scores<-lavPredict(cfa.fit)
scores<-unname(as.matrix(scores))

anglerData_mod$centrality<-scores

names(anglerData_mod)[24]<-"centrality"
```
Removed low-estimate indicators until CFI and TLI were acceptable
days fished wasn't a good predictor. The small sample size is also not great

weather data

```{r}
data.indexed$date<-ymd(data.indexed$date)

woodruff<-read_csv(here::here("data","ntl17_1_v19_woodruff.csv"))
minocqua<-read_csv(here::here("data","ntl18_v9_minocqua.csv"))

woodruff_mod<-woodruff%>%
  select(sampledate, avg_air_temp, avg_wind_speed, avg_barom_pres_mbar, avg_par)%>%
  mutate(sampledate=mdy(sampledate))%>%
  filter(year(sampledate)%in%c("2018","2019"))

minocqua_mod<-minocqua%>%
  select(sampledate, precip)%>%
  mutate(sampledate=mdy(sampledate))%>%
  filter(year(sampledate)%in%c("2018","2019"))

weather<-woodruff_mod%>%
  left_join(minocqua_mod, by="sampledate")%>%
  filter(sampledate%in%data.indexed$date)%>%
  # now I'm going to scale all of these values
  mutate(across(avg_air_temp:precip, ~scale(.x, center=T, scale=T)))

names(weather)[2:6]<-paste0(names(weather)[2:6], "_sc")
names(weather)[1]<-"date"

weather_moon<-weather%>%
  mutate(illum_sc=scale(lunar.illumination.mean(date), center=T, scale=T))


data.indexed.weather<-data.indexed%>%
  left_join(weather_moon, by="date")
```
added photosynthetically active radiation and phase of moon

```{r}

data.list<-list(N=nrow(data.indexed),
                A=max(data.indexed$A),
                D=max(data.indexed$D),
                L=max(data.indexed$L),
                AA=data.indexed$A,
                DD=data.indexed$D,
                LL=data.indexed$L,
                lmbCatch=data.indexed$lmbCatch,
                log_effort=data.indexed$log_effort,
                sumCtMt=lakeID$sumCtMt,
                sumRt=lakeID$sumRt,
                surfaceArea=lakeID$surfaceArea,
                P = 234,
                lakeID_pred=lakeID_pred,
                anglerID_pred=anglerID_pred,
                dateID_pred=dateID_pred,
                effort_pred = rep(log(4), 234))
                # centrality=anglerData_mod$centrality,
                # daysFished_sc=anglerData_mod$daysFishedPast_sc,
                # avg_air_temp_sc=as.vector(weather_moon$avg_air_temp_sc),
                # avg_wind_speed_sc=as.vector(weather_moon$avg_wind_speed_sc),
                # avg_barom_pres_mbar_sc=as.vector(weather_moon$avg_barom_pres_mbar_sc),
                # avg_par_sc=as.vector(weather_moon$avg_par_sc),
                # precip_sc=as.vector(weather_moon$precip_sc),
                # illum_sc=as.vector(weather_moon$illum_sc)
                #)

pred_df<-data.frame(lakeID=lakeID_pred,
                    anglerID=anglerID_pred,
                    dateID=dateID_pred)
```

```{r}

real_fit<-stan(file="noncentered.hierarchical.LINEARIZED.stan",
                 data=data.list,
                 #init=hier.inits,
                 control=list(stepsize=0.1, max_treedepth=15),
                 chains=4,
                 warmup=1000,
                 iter=3000,
                 cores=4,
                 refresh=0)
#launch_shinystan(real_fit)

draws<-extract(real_fit)

```

Visualizing results

Making charts

```{r}
part_var<-data.frame(glmm_r2=draws$glmm_r2,
                     fixed_r2=draws$fixed_r2,
                     ICC_adj=draws$ICC_adj,
                     ICC_adj_a=draws$ICC_adj_a,
                     ICC_adj_d=draws$ICC_adj_d,
                     ICC_adj_l=draws$ICC_adj_l,
                     part_r2_popDensity=draws$part_r2_popDensity,
                     vpc_a=draws$vpc_a,
                     vpc_d=draws$vpc_d,
                     vpc_l=draws$vpc_l)

ggplot(part_var)+
  geom_density(aes(x=glmm_r2))+
  theme_bw()

ggplot(part_var)+
  geom_density(aes(x=fixed_r2))+
  theme_bw()


ggplot(part_var)+
  geom_density(aes(x=ICC_adj))+
  theme_bw()

ggplot(part_var)+
  geom_density(aes(x=ICC_adj_a))+
  theme_bw()
ggplot(part_var)+
  geom_density(aes(x=ICC_adj_d))+
  theme_bw()
ggplot(part_var)+
  geom_density(aes(x=ICC_adj_l))+
  theme_bw()



ggplot(part_var)+
  geom_density(aes(x=part_r2_popDensity), fill="purple")+
  theme_bw()
# model run problems if I bound lower limit at 0


angler<-ggplot(part_var)+
  geom_density(aes(x=vpc_a), fill="orange")+
  ggtitle("Angler VPC")+
  xlim(0,1)+
  theme_bw()

day<-ggplot(part_var)+
  geom_density(aes(x=vpc_d), fill="yellow")+
  ggtitle("Date VPC")+
  xlim(0,1)+
  theme_bw()

lake<-ggplot(part_var)+
  geom_density(aes(x=vpc_l), fill="blue")+
  ggtitle("Lake VPC")+
  xlim(0,1)+
  theme_bw()

library(cowplot)

plot_grid(angler, day, lake, nrow=1)

```




I'm not sure that's going to work integrated into the model..

```{r}
dateEffect<-draws$log_q_d

dateEffectMean<-colMeans(dateEffect)
dateEffectSD<-apply(dateEffect, 2, sd)

weather_moon$meanEffect<-dateEffectMean
weather_moon$sdEffect<-dateEffectSD

weather_effect<-weather_moon%>%
  mutate(upperCI=meanEffect+1.96*sdEffect,
         lowerCI=meanEffect-1.96*sdEffect)



ggplot(weather_effect)+
  geom_point(aes(x=date, y=meanEffect))+
  geom_errorbar(aes(x=date, y=meanEffect, ymin=lowerCI, ymax=upperCI))

```

oof, those are WIDE

```{r}
chart.Correlation(weather_effect[,c(2:8)])

weather_mod<-lm(meanEffect~avg_air_temp_sc+avg_wind_speed_sc+avg_barom_pres_mbar_sc+avg_par_sc+precip_sc+illum_sc, data=weather_effect)
plot(weather_mod)
summary(weather_mod)
```


Angler effects?

```{r}
anglerEffect<-draws$log_q_a

anglerEffectMean<-colMeans(anglerEffect)
anglerEffectSD<-apply(anglerEffect, 2, sd)

anglerData_mod$A<-anglerData_mod$anglerID

anglerEffect<-anglerID%>%
  left_join(anglerData_mod, by="A")

anglerEffect$meanEffect<-anglerEffectMean
anglerEffect$sdEffect<-anglerEffectSD

angler_effect<-anglerEffect%>%
  mutate(upperCI=meanEffect+1.96*sdEffect,
         lowerCI=meanEffect-1.96*sdEffect)

ggplot(angler_effect)+
  geom_point(aes(x=A, y=meanEffect))+
  geom_errorbar(aes(x=A, y=meanEffect, ymin=lowerCI, ymax=upperCI))

```

```{r}
chart.Correlation(angler_effect[,c(25:27)])
```

```{r}
angler_mod<-lm(meanEffect~daysFishedPast_sc+centrality, data=angler_effect)
plot(angler_mod)
summary(angler_mod)
```
```{r}
lakeEffect<-draws$log_q_l

lakeEffectMean<-colMeans(lakeEffect)
lakeEffectSD<-apply(lakeEffect, 2, sd)

lakeEffect_mod<-data.frame(lakeEffectMean=lakeEffectMean,
                           lakeEffectSD=lakeEffectSD,
                           upperCI=lakeEffectMean+1.96*lakeEffectSD,
                           lowerCI=lakeEffectMean-1.96*lakeEffectSD)

lakeEffect<-cbind.data.frame(lakeID, lakeEffect_mod)


ggplot(lakeEffect)+
  geom_point(aes(x=L, y=lakeEffectMean))+
  geom_errorbar(aes(x=L, y=lakeEffectMean, ymin=lowerCI, ymax=upperCI))

```

I bet there's a size effect (or shoreline length effect) because bass got caught less often in the bigger lakes.

```{r}
plot(lakeEffect$lakeEffectMean~lakeEffect$surfaceArea)
```
```{r}
lakes<-dbTable("lakes", fpath=db.dir)

samples_electro<-dbTable("fish_samples", fpath=db.dir)
  filter(projectID==38 & gear=="BE")

samples_angling<-dbTable("fish_samples", fpath=db.dir)%>%
  filter(projectID==38 & gear=="AN")

dbTableList(db.dir, db)



```
looking at Colin's hyperstability paper, they used a different mark recap method for population estimates because they had individual fish capture histories
