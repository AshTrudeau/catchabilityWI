---
title: "integrated population estimate and catch equation"
output: html_document
date: "2024-05-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, here, lubridate, lme4, rstan, shinystan, truncnorm, MFEUtilities)
```

Make 'fake' data. (catch is simulated, population densities are real)

```{r}
set.seed(34)

catch.fun.err<-function(effort, q_mu, q_d, q_a, q_l, popDensity, beta, error){
  catch=(effort*(q_mu+q_d+q_a+q_l)*popDensity^beta)*error
  return(catch)
}
# method of moments for getting lognormal distribution to draw from
mom.lognorm.mu<-function(mean, var){
  log(mean/sqrt((var/mean^2)+1))
}
mom.lognorm.sigma<-function(mean, var){
  sqrt(log((var/mean^2)+1))
}

# draw 'observed' population densities from distribution of draws for simulation of catch

popDensityObs<-read_csv(here::here("output","bayesian.pop.density.csv"))
popDensityObs$...1<-NULL

popDensity.param<-popDensityObs%>%
  mutate(var=sd.popDensity^2,
         mu=mom.lognorm.mu(mean.popDensity, var),
         sigma=mom.lognorm.sigma(mean.popDensity, var),
         popDensityDraw=rlnorm(nrow(popDensityObs), mu, sigma))

# output from population estimates needed for simulating data  
pe.data<-read_csv(here::here("output","recap.sumctmt.sumrt.surfaceArea.csv"))

```

and the rest of the simulated data

```{r}
# 90 unique dates
D<-90
# 20 unique anglers
A<-20
# 10 unique lakes
L<-13

q_d<-rlnorm(D, -1, 0.5)
q_a<-rlnorm(A, -2, 0.2)
q_l<-rlnorm(L, -2, 0.01)

q_mu<-0.2

popDensity<-popDensity.param$popDensityDraw
beta<-0.25

# D, A, and L indexes and their q values
dates<-data.frame(D=seq(1:D), q_d=q_d)
anglers<-data.frame(A=seq(1:A), q_a=q_a)
lakes<-data.frame(L=seq(1:L), q_l=q_l, sumCtMt=pe.data$sumCtMt, sumRt=pe.data$sumRt, surfaceArea=pe.data$surfaceArea, popDensity=popDensity)

# sample randomly with replacement from anglers and lakes for each date. then left_join approprate q values by A, D, and L selection

lakeSamples<-sample(lakes$L, 180, replace=TRUE)
anglerSamples<-sample(anglers$A, 540, replace=TRUE)


# 2 lakes visited each day, three anglers at each lake
fake.df.hier<-data.frame(D=rep(dates$D, each=6),
                         L=rep(lakeSamples, each=3),
                         A=anglerSamples)%>%
  left_join(dates, by="D")%>%
  left_join(anglers, by="A")%>%
  left_join(lakes, by="L")%>%
  mutate(beta=rep(0.25),
         q_mu=rep(0.1),
         effort=rlnorm(540, meanlog=1.25, sdlog=0.25),
         error=rlnorm(540, meanlog=0, sdlog=0.3),
         popDensity=popDensity,
         lmbCatch=floor(catch.fun.err(effort, q_mu, q_d, q_a, q_l, popDensity, beta, error)))

# that's a lot of it, but I still need sumCtMt, surfaceArea, and sumRt



fake.data.hier<-list(N=nrow(fake.df.hier),
                     D=D,
                     L=L,
                     A=A,
                     DD=fake.df.hier$D,
                     LL=fake.df.hier$L,
                     AA=fake.df.hier$A,
                     log_effort=log(fake.df.hier$effort),
                     lmbCatch=fake.df.hier$lmbCatch,
                    # surfaceArea=lakes$surfaceArea,
                    # sumCtMt=lakes$sumCtMt,
                    # sumRt=lakes$sumRt
                    surfaceArea=fake.df.hier$surfaceArea,
                    sumCtMt=fake.df.hier$sumCtMt,
                    sumRt=fake.df.hier$sumRt)

fake_fit_hier<-stan(file="noncentered.hierarchical.LINEARIZED.stan",
                 data=fake.data.hier,
                 #init=hier.inits,
                 control=list(stepsize=0.1, max_treedepth=15),
                 chains=4,
                 warmup=1000,
                 iter=2000,
                 cores=4,
                 refresh=0)
launch_shinystan(fake_fit_hier)
```

Time to fit to real data!

Pull raw data from MFE database
```{r}


# raw catch data
wd<-getwd()
db.dir<-paste0(wd, "/MFEdb/")
db<-"MFEdb_20220405.db"

dbTableList(db.dir, db)

lakes<-dbTable("lakes", fpath=db.dir, dbname=db)

# lake data

lakes.key<-lakes%>%
  dplyr::select(lakeID, lakeName, lat, long, WBIC, surfaceArea)
# Found lake missing surface area--135.97 ha
lakes.key[lakes.key$lakeID=="FD","surfaceArea"]<-135.97


projects<-dbTable("projects", fpath=db.dir, dbname=db)

fishSamples<-dbTable("fish_samples", fpath=db.dir, dbname=db)%>%
  filter(projectID%in%c("37","38") & gear=="AN")

fishInfo<-dbTable("fish_info", fpath=db.dir, dbname=db)%>%
  filter(sampleID%in%fishSamples$sampleID)%>%
  filter(str_length(caughtBy)<4)%>%
  mutate(caughtBy=str_trim(caughtBy))%>%
  filter(otu=="largemouth_bass")%>%
  dplyr::select(projectID:caughtBy, comments)%>%
  # join fishing effort
  left_join(fishSamples[,c("lakeID","sampleID","dayOfYear","dateSample","dateTimeSample","crew","effort","effortUnits","nAnglers")], by="sampleID")

# catch rates for each angler trip, correcting for some ambiguous initials first

ALK.lake.date<-c("LV_20190608",
                 "SM_20190615",
                 "WN_20190617",
                 "BY_20190622")

AMK.lake.date<-c("DS_20190613",
                 "BOT_20190615",
                 "SM_20190621",
                 "BOT_20190624",
                 "NH_20190713")

long.crew<-fishSamples%>%
  group_by(sampleID)%>%
  summarize(crew=unique(crew),
            effort=unique(effort))%>%
  # split crew into columns and then pivot longer
  separate("crew", paste("angler", 1:3, sep="_"), sep=", ", extra="drop")%>%
  pivot_longer(cols=angler_1:angler_3, names_to="angler_num", values_to="caughtBy", values_drop_na=T)%>%
  mutate(caughtBy=ifelse(caughtBy=="CMI","CI", caughtBy))%>%
  mutate(date=str_split_fixed(sampleID, "_", 4)[,3],
         lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         lakeID_date=paste(lakeID, date, sep="_"))%>%
  mutate(caughtBy=ifelse(lakeID_date%in%AMK.lake.date, "AMK",
                         ifelse(lakeID_date%in%ALK.lake.date, "ALK", caughtBy)))
  
 #long.crew$date<-NULL
 #long.crew$lakeID<-NULL
 #long.crew$lakeID_date<-NULL
 
 
 all.data<-fishInfo%>%
  mutate(year=year(dateSample))%>%
  left_join(lakes.key, by="lakeID")
  

  
# now get catch rates from angling data and left join to long.crew. empty values can then be replaced with 0

cpue<-all.data%>%
  group_by(sampleID, caughtBy)%>%
  summarize(nCaught=n())



full.data<-long.crew%>%
  left_join(cpue, by=c("sampleID", "caughtBy"))%>%
  mutate(nCaught=ifelse(is.na(nCaught), 0, nCaught))



# join on mark recap data (sumCtRt and sumRt) and surface area

```


code for processing mark recap data

```{r}
fish_samples<-dbTable("fish_samples", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(useSampleMarkRecap=="yes")

# ok, we want to do projects 37 and 38 separately. 37 used AF (anal fin) tags, 38 used PIT tags
fish_info<-dbTable("fish_info", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(sampleID%in%fish_samples$sampleID)%>%
  filter(otu=="largemouth_bass")

fish_data<-inner_join(fish_samples, fish_info, by="sampleID")%>%
  mutate(lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         clipRecapture=as.numeric(clipRecapture),
         clipRecapture=ifelse(is.na(clipRecapture),0,clipRecapture),
         tagged=ifelse(clipApply=="AF", 1, 0))

samples<-unique(fish_data$sampleID)

lakes<-dbTable("lakes", fpath=db.dir)

fish_samples<-data.frame(sampleID=unique(fish_data$sampleID))%>%
  mutate(method=str_split_fixed(sampleID, "_", 6)[,5],
         sampleDate=str_split_fixed(sampleID, "_", 4)[,3],
         sampleTime=str_split_fixed(sampleID, "_", 5)[,4],
         date_time=ymd_hm(paste(sampleDate, sampleTime, sep="_")),
         # adjust sampleDates for night electrofishing--if method==BE and sampleTime is in the evening before midnight, add one day to date.
         adjust=ifelse(method=="BE" & sampleTime<2359 & sampleTime>1200, 1, 0),
         adj_sampleDate=as.character(ymd(sampleDate)+days(1)),
         batchDate=ifelse(adjust==1, adj_sampleDate, as.character(ymd(sampleDate))),
         batchDate_method=paste(batchDate, method, sep="_"))

fish_pe<-left_join(fish_data, fish_samples[,c("sampleID","batchDate_method")], by="sampleID")%>%
  group_by(lakeID, batchDate_method)%>%
  summarize(markedNow=sum(tagged, na.rm=T),
            recapturedNow=sum(clipRecapture))%>%
  mutate(marked_cum=cumsum(markedNow),
         markedPrior=lag(marked_cum),
         markedPrior=ifelse(is.na(markedPrior), 0, markedPrior),
         allFishCaught=markedNow+recapturedNow)%>%
  ungroup()

# let's filter to lakes that had at least 1 recapture

recap_count<-fish_pe%>%
  group_by(lakeID)%>%
  summarize(nRecap=sum(recapturedNow))%>%
  arrange(desc(nRecap))%>%
  filter(nRecap>0)

# surface area for Found lake was missing. Got it from WI DNR (find a lake tool) and converted to hectares
lakes[lakes$lakeID=="FD",]$surfaceArea<-136.0

fish_pe_recap<-fish_pe%>%
  filter(lakeID%in%recap_count$lakeID)%>%
  mutate(CtMt=allFishCaught*markedPrior)%>%
  group_by(lakeID)%>%
  summarize(sumCtMt=sum(CtMt),
            sumRt=sum(recapturedNow))%>%
  ungroup()%>%
  left_join(lakes[,c("lakeID","surfaceArea")], by="lakeID")

```
Now join those datasets and index the unique lakeIDs and caughtBy initials

```{r}
data.join<-full.data%>%
  filter(lakeID%in%fish_pe_recap$lakeID)%>%
  left_join(fish_pe_recap, by="lakeID")


lakeID<-data.frame(lakeID=unique(data.join$lakeID),
                   L=seq(1:13))

anglerID<-data.frame(caughtBy=unique(data.join$caughtBy),
                     A=seq(1:18))

dateID<-data.frame(date=unique(data.join$date),
                   D=seq(1:42))

data.indexed<-data.join%>%
  left_join(dateID, by="date")%>%
  left_join(anglerID, by="caughtBy")%>%
  left_join(lakeID, by="lakeID")%>%
  mutate(log_effort=log(effort))%>%
  rename("lmbCatch"=nCaught)

data.list<-list(N=nrow(data.indexed),
                A=max(data.indexed$A),
                D=max(data.indexed$D),
                L=max(data.indexed$L),
                AA=data.indexed$A,
                DD=data.indexed$D,
                LL=data.indexed$L,
                lmbCatch=data.indexed$lmbCatch,
                log_effort=data.indexed$log_effort,
                sumCtMt=data.indexed$sumCtMt,
                sumRt=data.indexed$sumRt,
                surfaceArea=data.indexed$surfaceArea)


real_fit<-stan(file="noncentered.hierarchical.LINEARIZED.stan",
                 data=data.list,
                 #init=hier.inits,
                 control=list(stepsize=0.1, max_treedepth=15),
                 chains=4,
                 warmup=1000,
                 iter=2000,
                 cores=4,
                 refresh=0)
launch_shinystan(real_fit)


  

```

zero effort values?