---
title: "Varying effects beta"
output: html_document
date: "2024-08-05"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(tidyverse, here, lubridate, lme4, loo, rstan, shinystan, truncnorm, MFEUtilities, RColorBrewer, cowplot, bayesplot, cmdstanr, posterior)
```

Pull raw data from MFE database
```{r}
rm(list=ls())

# raw catch data
wd<-getwd()
db.dir<-paste0(wd, "/MFEdb/")
db<-"MFEdb_20220405.db"

dbTableList(db.dir, db)

lakes<-dbTable("lakes", fpath=db.dir, dbname=db)
#crew<-dbTable("crew", fpath=db.dir, dbname=db)%>%
#  filter(year%in%c("2018","2019"))
#write.csv(crew, "crew.csv")

# lake data

lakes.key<-lakes%>%
  dplyr::select(lakeID, lakeName, lat, long, WBIC, surfaceArea)
# Found lake missing surface area--135.97 ha
lakes.key[lakes.key$lakeID=="FD","surfaceArea"]<-135.97


projects<-dbTable("projects", fpath=db.dir, dbname=db)

fishSamples<-dbTable("fish_samples", fpath=db.dir, dbname=db)%>%
  filter(projectID%in%c("37") & gear=="AN")%>%
    mutate(nAnglers=as.numeric(nAnglers),
    effort=effort/nAnglers)


fishInfo<-dbTable("fish_info", fpath=db.dir, dbname=db)%>%
  filter(sampleID%in%fishSamples$sampleID)%>%
  filter(str_length(caughtBy)<4)%>%
  mutate(caughtBy=str_trim(caughtBy))%>%
  filter(otu=="largemouth_bass")%>%
  dplyr::select(projectID:caughtBy, comments)%>%
  # join fishing effort
  left_join(fishSamples[,c("lakeID","sampleID","dayOfYear","dateSample","dateTimeSample","crew","effort","effortUnits","nAnglers")], by="sampleID")

# catch rates for each angler trip, correcting for some ambiguous initials first

ALK.lake.date<-c("LV_20190608",
                 "SM_20190615",
                 "WN_20190617",
                 "BY_20190622")

AMK.lake.date<-c("DS_20190613",
                 "BOT_20190615",
                 "SM_20190621",
                 "BOT_20190624",
                 "NH_20190713")

long.crew<-fishSamples%>%
  group_by(sampleID)%>%
  summarize(crew=unique(crew),
            effort=unique(effort))%>%
  # split crew into columns and then pivot longer
  separate("crew", paste("angler", 1:3, sep="_"), sep=", ", extra="drop")%>%
  pivot_longer(cols=angler_1:angler_3, names_to="angler_num", values_to="caughtBy", values_drop_na=T)%>%
  mutate(caughtBy=ifelse(caughtBy=="CMI","CI", caughtBy))%>%
  mutate(date=str_split_fixed(sampleID, "_", 4)[,3],
         lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         lakeID_date=paste(lakeID, date, sep="_"))%>%
  mutate(caughtBy=ifelse(lakeID_date%in%AMK.lake.date, "AMK",
                         ifelse(lakeID_date%in%ALK.lake.date, "ALK", caughtBy)))
  
 #long.crew$date<-NULL
 #long.crew$lakeID<-NULL
 #long.crew$lakeID_date<-NULL
 
 
 all.data<-fishInfo%>%
  mutate(year=year(dateSample))%>%
  left_join(lakes.key, by="lakeID")
  

  
# now get catch rates from angling data and left join to long.crew. empty values can then be replaced with 0

cpue<-all.data%>%
  group_by(sampleID, caughtBy)%>%
  summarize(nCaught=n())



full.data<-long.crew%>%
  left_join(cpue, by=c("sampleID", "caughtBy"))%>%
  mutate(nCaught=ifelse(is.na(nCaught), 0, nCaught))



# join on mark recap data (sumCtRt and sumRt) and surface area

```


code for processing mark recap data

```{r}
fish_samples<-dbTable("fish_samples", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(useSampleMarkRecap=="yes")

# ok, we want to do projects 37 and 38 separately. 37 used AF (anal fin) tags, 38 used PIT tags
fish_info<-dbTable("fish_info", fpath=db.dir)%>%
  filter(projectID%in%c("37"))%>%
  filter(sampleID%in%fish_samples$sampleID)%>%
  filter(otu=="largemouth_bass")

fish_data<-inner_join(fish_samples, fish_info, by="sampleID")%>%
  mutate(lakeID=str_split_fixed(sampleID, "_", 2)[,1],
         clipRecapture=as.numeric(clipRecapture),
         clipRecapture=ifelse(is.na(clipRecapture),0,clipRecapture),
         tagged=ifelse(clipApply=="AF", 1, 0))

samples<-unique(fish_data$sampleID)

lakes<-dbTable("lakes", fpath=db.dir)

fish_samples<-data.frame(sampleID=unique(fish_data$sampleID))%>%
  mutate(method=str_split_fixed(sampleID, "_", 6)[,5],
         sampleDate=str_split_fixed(sampleID, "_", 4)[,3],
         sampleTime=str_split_fixed(sampleID, "_", 5)[,4],
         date_time=ymd_hm(paste(sampleDate, sampleTime, sep="_")),
         # adjust sampleDates for night electrofishing--if method==BE and sampleTime is in the evening before midnight, add one day to date.
         adjust=ifelse(method=="BE" & sampleTime<2359 & sampleTime>1200, 1, 0),
         adj_sampleDate=as.character(ymd(sampleDate)+days(1)),
         batchDate=ifelse(adjust==1, adj_sampleDate, as.character(ymd(sampleDate))),
         batchDate_method=paste(batchDate, method, sep="_"))

fish_pe<-left_join(fish_data, fish_samples[,c("sampleID","batchDate_method")], by="sampleID")%>%
  group_by(lakeID, batchDate_method)%>%
  summarize(markedNow=sum(tagged, na.rm=T),
            recapturedNow=sum(clipRecapture))%>%
  mutate(marked_cum=cumsum(markedNow),
         markedPrior=lag(marked_cum),
         markedPrior=ifelse(is.na(markedPrior), 0, markedPrior),
         allFishCaught=markedNow+recapturedNow)%>%
  ungroup()

# let's filter to lakes that had at least 1 recapture

recap_count<-fish_pe%>%
  group_by(lakeID)%>%
  summarize(nRecap=sum(recapturedNow))%>%
  arrange(desc(nRecap))%>%
  filter(nRecap>0)

recap_over_1<-filter(recap_count, nRecap>1)

# surface area for Found lake was missing. Got it from WI DNR (find a lake tool) and converted to hectares
lakes[lakes$lakeID=="FD",]$surfaceArea<-136.0

fish_pe_recap<-fish_pe%>%
  filter(lakeID%in%recap_count$lakeID)%>%
  mutate(CtMt=allFishCaught*markedPrior)%>%
  group_by(lakeID)%>%
  summarize(sumCtMt=sum(CtMt),
            sumRt=sum(recapturedNow))%>%
  ungroup()%>%
  left_join(lakes[,c("lakeID","surfaceArea")], by="lakeID")

```

```{r}
data.join<-full.data%>%
  filter(lakeID%in%fish_pe_recap$lakeID)%>%
  left_join(fish_pe_recap, by="lakeID")


lakeID<-data.frame(lakeID=fish_pe_recap$lakeID,
                   L=seq(1:13),
                   sumCtMt=fish_pe_recap$sumCtMt,
                   sumRt=fish_pe_recap$sumRt,
                   surfaceArea=fish_pe_recap$surfaceArea)

anglerID<-data.frame(caughtBy=unique(data.join$caughtBy),
                     A=seq(1:18))

dateID<-data.frame(date=unique(data.join$date),
                   D=seq(1:42))

data.indexed<-data.join%>%
  left_join(dateID, by="date")%>%
  left_join(anglerID, by="caughtBy")%>%
  left_join(lakeID, by="lakeID")%>%
  mutate(log_effort=log(effort))%>%
  rename("lmbCatch"=nCaught)


```

```{r}
data.list<-list(N=nrow(data.indexed),
                A=max(data.indexed$A),
                D=max(data.indexed$D),
                L=max(data.indexed$L),
                AA=data.indexed$A,
                DD=data.indexed$D,
                LL=data.indexed$L,
                lmbCatch=data.indexed$lmbCatch,
                log_effort=data.indexed$log_effort,
                sumCtMt=lakeID$sumCtMt,
                sumRt=lakeID$sumRt,
                surfaceArea=lakeID$surfaceArea
                )

# trying a run that generates posterior predictions from the random effects I already have (rather than generating new ones)

fit_vary_slope<-stan(file="varying.effects.beta.stan",
                 data=data.list,
                 #init=hier.inits,
                 control=list(stepsize=0.1, max_treedepth=15),
                 chains=4,
                 warmup=1000,
                 iter=3000,
                 cores=4,
                 refresh=0)

#launch_shinystan(fit_vary_slope)
post<-extract(fit_vary_slope)

angler_effect<-post$angler_effect
mean_angler_effect<-colMeans(angler_effect)

plot(mean_angler_effect[,2]~mean_angler_effect[,1])

```
negative correlation--at a higher intercept, there tends to be a lower beta, or more hyperstable catch rates (which makes sense)



Can I plot the draws of slope and intercept by angler? 

```{r}
angler_intercept<-as.data.frame(angler_effect[,,1])
names(angler_intercept)<-c(paste("angler", c(1:18), sep="_"))

angler_int_long<-angler_intercept%>%
  pivot_longer(cols=everything(), names_to = "angler", values_to="intercept")


angler_slope<-as.data.frame(angler_effect[,,2])
names(angler_slope)<-paste0("angler_", seq(1:18))

angler_slope_long<-angler_slope%>%
  pivot_longer(cols=everything(), names_to="angler", values_to="slope")

sum(angler_int_long$angler!=angler_slope_long$angler)
```

```{r}
# join is very slow--unnecessary? probably can just bind together
angler_params<-cbind.data.frame(angler_int_long, angler_slope_long[,c("slope")])

ggplot(angler_params)+
  geom_density(aes(x=intercept))+
  geom_vline(xintercept=0, linetype="dashed")+
  facet_wrap(vars(angler))+
  theme_bw()

ggplot(angler_params)+
  geom_density(aes(x=slope))+
  geom_vline(xintercept=0, linetype="dashed")+
  facet_wrap(vars(angler))+
  theme_bw()

```
now sd for intercept and slope among anglers

```{r}
sd_angler_params<-as.data.frame(post$sigma_angler)
names(sd_angler_params)<-c("sd_intercept","sd_slope")




ggplot(sd_angler_params)+
  geom_density(aes(x=sd_intercept))+
  geom_vline(xintercept=0, linetype="dashed")+
  ggtitle("sd_intercept")+
  theme_bw()

ggplot(sd_angler_params)+
  geom_density(aes(x=sd_slope))+
  geom_vline(xintercept=0, linetype="dashed")+
  ggtitle("sd_slope")+
  theme_bw()


```




Function to pivot, and visualize for the rest of the parameters
```{r}
# give it a named df
plot_param<-function(posterior, param.name){
  param.df=as.data.frame(posterior[[param.name]])
  long=pivot_longer(param.df, cols=everything(), names_to=param.name)
  ggplot(long)+
    geom_density(aes(x=value))+
    #facet_wrap(var(param.name))+
    geom_vline(xintercept=0, linetype="dashed")+
    ggtitle(param.name)+
    theme_bw()
}

plot_param(post, "phi")
plot_param(post, "angler_global")
plot_param(post, "sigma_date")
plot_param(post, "sigma_lake")

```
population densities
```{r}
pop.density<-as.data.frame(post$popDensity)
names(pop.density)<-paste0("lake_", seq(1:13))

pop.density.long<-pop.density%>%
  pivot_longer(cols=everything(), names_to="lake", values_to="popDensity")

ggplot(pop.density.long)+
  geom_density(aes(x=popDensity))+
  facet_wrap(vars(lake), scales="free_x")+
  ylim(0,1)+
  geom_vline(xintercept=0, linetype="dashed")+
  theme_bw()

```

oof, those are pretty bad population density estimates


```{r}
pred_draw<-post$catch_pred[1,]
obs_catch<-data.indexed$lmbCatch

ggplot()+
  geom_point(aes(x=obs_catch, y=pred_draw))+
  geom_abline(slope=1, intercept=0)+
  theme_bw()

```

```{r}
ppc_dens_overlay(data.list$lmbCatch, post$catch_pred[c(1:100),])
```
compare to original fit

```{r}
fit_vanilla<-stan(file="noncentered.hierarchical.LINEARIZED.stan",
                 data=data.list,
                 #init=hier.inits,
                 control=list(stepsize=0.1, max_treedepth=15),
                 chains=4,
                 warmup=1000,
                 iter=3000,
                 cores=4,
                 refresh=0)
post_vanilla<-extract(fit_vanilla)
ppc_dens_overlay(data.list$lmbCatch, post_vanilla$posterior_pred_check[c(1:100),])

```



Try generating new random effects? see how different it is
```{r}
fit_slope_zinf<-stan(file="vary.beta.by.angler.zinf.stan",
                 data=data.list,
                 #init=hier.inits,
                 control=list(stepsize=0.1, max_treedepth=15),
                 chains=4,
                 warmup=1000,
                 iter=3000,
                 cores=4,
                 refresh=0)

post_slope_zinf<-extract(fit_slope_zinf)
ppc_dens_overlay(data.list$lmbCatch, post_slope_zinf$catch_pred[c(1:100),])




```

add zinf?
lol no
